{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORCE_MEM_EFFICIENT_ATTN= 1 @UNET:QKVATTENTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TheCa\\.conda\\envs\\deepfloyd\\lib\\site-packages\\huggingface_hub\\file_download.py:1104: FutureWarning: The `force_filename` parameter is deprecated as a new caching system, which keeps the filenames as they are on the Hub, is now in place.\n",
      "  warnings.warn(\n",
      "unet\\diffusion_pytorch_model.safetensors not found\n",
      "Keyword arguments {'token': None} are not expected by StableDiffusionUpscalePipeline and will be ignored.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004998683929443359,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4d54a5b3af47a9b9ba4dceca837fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['FORCE_MEM_EFFICIENT_ATTN'] = \"1\"\n",
    "from deepfloyd_if.modules import IFStageI, IFStageII, StableStageIII\n",
    "from deepfloyd_if.modules.t5 import T5Embedder\n",
    "\n",
    "import torch\n",
    "\n",
    "device = 'cuda:0'\n",
    "f_I = IFStageI('IF-I-XL-v1.0', device=device, model_kwargs={\"precision\":\"16\"})\n",
    "if_II = IFStageII('IF-II-L-v1.0', device=device, model_kwargs={\"precision\":\"16\"})\n",
    "if_III = StableStageIII('stable-diffusion-x4-upscaler', device=device, model_kwargs={\"precision\":\"16\"})\n",
    "t5 = T5Embedder(device=\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def dream(\n",
    "    t5,\n",
    "    if_I,\n",
    "    if_II=None,\n",
    "    if_III=None,\n",
    "    *,\n",
    "    prompt,\n",
    "    style_prompt=None,\n",
    "    negative_prompt=None,\n",
    "    seed=None,\n",
    "    aspect_ratio='1:1',\n",
    "    if_I_kwargs=None,\n",
    "    if_II_kwargs=None,\n",
    "    if_III_kwargs=None,\n",
    "    progress=True,\n",
    "    return_tensors=False,\n",
    "    disable_watermark=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate pictures using text description!\n",
    "\n",
    "    :param optional dict if_I_kwargs:\n",
    "        \"dynamic_thresholding_p\": 0.95, [0.5, 1.0] it controls color saturation on high cfg values\n",
    "        \"dynamic_thresholding_c\": 1.5, [1.0, 15.0] clips the limiter to avoid greyish images on high limiter values\n",
    "        \"guidance_scale\": 7.0, [1.0, 20.0] control the level of text understanding\n",
    "        \"positive_mixer\": 0.25, [0.0, 1.0] contribution of the second positive prompt, 0.0 - minimum, 1.0 - maximum\n",
    "        \"sample_timestep_respacing\": \"150\", see available modes IFBaseModule.respacing_modes or use custom\n",
    "\n",
    "    :param optional dict if_II_kwargs:\n",
    "        \"dynamic_thresholding_p\": 0.95, [0.5, 1.0] it controls color saturation on high cfg values\n",
    "        \"dynamic_thresholding_c\": 1.0, [1.0, 15.0] clips the limiter to avoid greyish images on high limiter values\n",
    "        \"guidance_scale\": 4.0, [1.0, 20.0] control the amount of texture and details in the final image\n",
    "        \"aug_level\": 0.25, [0.0, 1.0] adds additional augmentation to generate more realistic images\n",
    "        \"positive_mixer\": 0.5, [0.0, 1.0] contribution of the second positive prompt, 0.0 - minimum, 1.0 - maximum\n",
    "        \"sample_timestep_respacing\": \"smart50\", see available modes IFBaseModule.respacing_modes or use custom\n",
    "\n",
    "    :param deepfloyd_if.modules.IFStageI if_I: obj\n",
    "    :param deepfloyd_if.modules.IFStageII if_II: obj\n",
    "    :param deepfloyd_if.modules.IFStageIII if_III: obj\n",
    "    :param deepfloyd_if.modules.T5Embedder t5: obj\n",
    "\n",
    "    :param int seed: int, in case None will use random value\n",
    "    :param aspect_ratio:\n",
    "    :param str prompt: text hint/description\n",
    "    :param str style_prompt: text hint/description for style\n",
    "    :param str negative_prompt: text hint/description for negative prompt, will use it as unconditional emb\n",
    "    :param progress:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if seed is None:\n",
    "        seed = int((datetime.utcnow().timestamp() * 10 ** 6) % (2 ** 32 - 1))\n",
    "    if_I.seed_everything(seed)\n",
    "\n",
    "    if isinstance(prompt, str):\n",
    "        prompt = [prompt]\n",
    "    if_I.model.to(\"cpu\")\n",
    "    t5.device=\"cuda\"\n",
    "    t5.model.to(\"cuda\")\n",
    "    t5_embs = t5.get_text_embeddings(prompt)\n",
    "    t5.model.to(\"cpu\")\n",
    "    if_I.model.to(\"cuda\")\n",
    "    if_I_kwargs = if_I_kwargs or {}\n",
    "    if_I_kwargs['seed'] = seed\n",
    "    if_I_kwargs['t5_embs'] = t5_embs\n",
    "    if_I_kwargs['aspect_ratio'] = aspect_ratio\n",
    "    if_I_kwargs['progress'] = progress\n",
    "\n",
    "    if style_prompt is not None:\n",
    "        if isinstance(style_prompt, str):\n",
    "            style_prompt = [style_prompt]\n",
    "        style_t5_embs = t5.get_text_embeddings(style_prompt)\n",
    "        if_I_kwargs['style_t5_embs'] = style_t5_embs\n",
    "        if_I_kwargs['positive_t5_embs'] = style_t5_embs\n",
    "\n",
    "    if negative_prompt is not None:\n",
    "        if isinstance(negative_prompt, str):\n",
    "            negative_prompt = [negative_prompt]\n",
    "        negative_t5_embs = t5.get_text_embeddings(negative_prompt)\n",
    "        if_I_kwargs['negative_t5_embs'] = negative_t5_embs\n",
    "\n",
    "    stageI_generations, _ = if_I.embeddings_to_image(**if_I_kwargs)\n",
    "    pil_images_I = if_I.to_images(stageI_generations, disable_watermark=disable_watermark)\n",
    "\n",
    "    result = {'I': pil_images_I}\n",
    "\n",
    "    if if_II is not None:\n",
    "        if_II_kwargs = if_II_kwargs or {}\n",
    "        if_II_kwargs['low_res'] = stageI_generations\n",
    "        if_II_kwargs['seed'] = seed\n",
    "        if_II_kwargs['t5_embs'] = t5_embs\n",
    "        if_II_kwargs['progress'] = progress\n",
    "        if_II_kwargs['style_t5_embs'] = if_I_kwargs.get('style_t5_embs')\n",
    "        if_II_kwargs['positive_t5_embs'] = if_I_kwargs.get('positive_t5_embs')\n",
    "\n",
    "        stageII_generations, _meta = if_II.embeddings_to_image(**if_II_kwargs)\n",
    "        pil_images_II = if_II.to_images(stageII_generations, disable_watermark=disable_watermark)\n",
    "\n",
    "        result['II'] = pil_images_II\n",
    "    else:\n",
    "        stageII_generations = None\n",
    "\n",
    "    if if_II is not None and if_III is not None:\n",
    "        if_III_kwargs = if_III_kwargs or {}\n",
    "\n",
    "        stageIII_generations = []\n",
    "        for idx in range(len(stageII_generations)):\n",
    "            if if_III.use_diffusers:\n",
    "                if_III_kwargs['prompt'] = prompt[idx: idx+1]\n",
    "\n",
    "            if_III_kwargs['low_res'] = stageII_generations[idx:idx+1]\n",
    "            if_III_kwargs['seed'] = seed\n",
    "            if_III_kwargs['t5_embs'] = t5_embs[idx:idx+1]\n",
    "            if_III_kwargs['progress'] = progress\n",
    "            style_t5_embs = if_I_kwargs.get('style_t5_embs')\n",
    "            if style_t5_embs is not None:\n",
    "                style_t5_embs = style_t5_embs[idx:idx+1]\n",
    "            positive_t5_embs = if_I_kwargs.get('positive_t5_embs')\n",
    "            if positive_t5_embs is not None:\n",
    "                positive_t5_embs = positive_t5_embs[idx:idx+1]\n",
    "            if_III_kwargs['style_t5_embs'] = style_t5_embs\n",
    "            if_III_kwargs['positive_t5_embs'] = positive_t5_embs\n",
    "\n",
    "            _stageIII_generations, _meta = if_III.embeddings_to_image(**if_III_kwargs)\n",
    "            stageIII_generations.append(_stageIII_generations)\n",
    "\n",
    "        stageIII_generations = torch.cat(stageIII_generations, 0)\n",
    "        pil_images_III = if_III.to_images(stageIII_generations, disable_watermark=disable_watermark)\n",
    "\n",
    "        result['III'] = pil_images_III\n",
    "    else:\n",
    "        stageIII_generations = None\n",
    "\n",
    "    if return_tensors:\n",
    "        return result, (stageI_generations, stageII_generations, stageIII_generations)\n",
    "    else:\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'T5Embedder' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mi:\\python\\if\\if.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/i%3A/python/if/if.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39multra close-up color photo portrait of rainbow owl with deer horns in the woods\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/i%3A/python/if/if.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/i%3A/python/if/if.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m t5\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/i%3A/python/if/if.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m result \u001b[39m=\u001b[39m dream(\n\u001b[0;32m      <a href='vscode-notebook-cell:/i%3A/python/if/if.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     t5\u001b[39m=\u001b[39mt5, if_I\u001b[39m=\u001b[39mf_I, if_II\u001b[39m=\u001b[39mif_II, if_III\u001b[39m=\u001b[39mif_III,\n\u001b[0;32m      <a href='vscode-notebook-cell:/i%3A/python/if/if.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     prompt\u001b[39m=\u001b[39m[prompt]\u001b[39m*\u001b[39mcount,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/python/if/if.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     },\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/python/if/if.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/python/if/if.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m if_III\u001b[39m.\u001b[39mshow(result[\u001b[39m'\u001b[39m\u001b[39mIII\u001b[39m\u001b[39m'\u001b[39m], size\u001b[39m=\u001b[39m\u001b[39m14\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'T5Embedder' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = 'ultra close-up color photo portrait of rainbow owl with deer horns in the woods'\n",
    "count = 1\n",
    "with torch.autocast(\"cuda\"):\n",
    "    result = dream(\n",
    "        t5=t5, if_I=f_I, if_II=if_II, if_III=if_III,\n",
    "        prompt=[prompt]*count,\n",
    "        seed=42,\n",
    "        if_I_kwargs={\n",
    "            \"guidance_scale\": 7.0,\n",
    "            \"sample_timestep_respacing\": \"smart100\",\n",
    "        },\n",
    "        if_II_kwargs={\n",
    "            \"guidance_scale\": 4.0,\n",
    "            \"sample_timestep_respacing\": \"smart50\",\n",
    "        },\n",
    "        if_III_kwargs={\n",
    "            \"guidance_scale\": 9.0,\n",
    "            \"noise_level\": 20,\n",
    "            \"sample_timestep_respacing\": \"75\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "if_III.show(result['III'], size=14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfloyd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
